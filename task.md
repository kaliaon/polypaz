# **PolyPath – Project Overview**

### **Purpose**

PolyPath is an AI-driven, text-based language learning platform that personalizes the learning path for each user. It combines adaptive AI-generated content, interactive exercises, and dialogue-based tutoring to deliver a personalized, data-informed language acquisition experience.

### **Core Concept**

* Users take a short placement test.
* The system determines their proficiency level (based on CEFR-like scaling).
* An AI model (Gemini 2.5) automatically generates a tailored learning roadmap.
* The learner progresses through interactive exercises and conversational practice.
* Performance and progress are tracked; feedback is personalized and adaptive.

### **Primary Components**

1. **Frontend**

   * Mobile (React Native)
   * Key interfaces: onboarding, roadmap, tasks, dialogue, statistics

2. **Backend (Django + Django REST Framework)**

   * Core APIs for roadmap, tasks, feedback, dialogue, and progress tracking
   * Integration with Gemini API for intelligent content and explanations
   * PostgreSQL for persistence; Redis for caching and rate limiting

3. **AI Layer (Gemini 2.5 API)**

   * Roadmap generation
   * Task creation and evaluation
   * Error feedback and explanation
   * Dialogue simulation (AI tutor)

4. **Data Model Overview**

   * **UserProfile** – learning preferences, target language, and progress summary
   * **PlacementTest** and **Result** – store test items and scores
   * **Roadmap** – structured modules generated by AI
   * **TaskTemplate / TaskInstance / Attempt** – exercises and learner responses
   * **DialogueSession / Turn** – text chat data with corrections
   * **ProgressSnapshot / Gamification** – learning statistics and motivational metrics

5. **Technology Stack**

   * **Backend:** Django, Django REST Framework, PostgreSQL, Redis
   * **Frontend:** React Native (mobile)
   * **AI Integration:** Gemini 2.5 API (server-side calls)
   * **Deployment:** Docker, CI/CD pipelines, cloud-based PaaS

6. **Expected Outcome**

   * Users receive a personalized learning journey from placement to mastery.
   * The system intelligently adapts based on learner data and AI feedback.
   * Progress is transparent, measurable, and motivating through gamification.

---

# **Staged Requirements**

---

## **Stage 1 – Super MVP (Essential Core)**

**Objective:** Deliver a functional, end-to-end learning flow that demonstrates the system’s main value.

### **Functional Requirements**

1. **Placement Test**

   * One per MVP language (Kazakh, Russian, English, Spanish).
   * 10–12 short items: multiple choice, cloze, and one translation.
   * Returns a CEFR estimate (A0, A1, A2).

2. **Roadmap Generation**

   * Gemini-generated JSON roadmap (3 modules max).
   * Fallback: static roadmap templates per language.
   * Modules include title, objectives, and checkpoint definition.

3. **Core Tasks**

   * Task types: multiple choice, fill-in-the-blank, translation.
   * Each task returns correctness, rule, and example contrast.

4. **AI Feedback**

   * Automatic correctness evaluation and concise rule-based explanation.

5. **Dialogue Mode (Prototype)**

   * One scenario (“At a Café”) with 10-turn limit.
   * AI provides inline correction and one reformulation.

6. **Basic Progress Tracking**

   * Per-module accuracy percentage.
   * Tasks attempted and last activity date.

7. **Gamification (Seed)**

   * XP gain per completed task.
   * Daily streak counter.

### **Non-Functional Requirements**

* Stable AI schema validation and fallback to static data.
* Response time < 2 seconds for standard task feedback.
* User flow: login → placement → roadmap → tasks → feedback → progress.

---

## **Stage 2 – MVP+ (Adaptation and Reliability)**

**Objective:** Introduce adaptivity, stronger feedback, and error analysis to enhance learning quality.

### **Functional Requirements**

1. **Adaptive Difficulty**

   * System adjusts task difficulty up or down based on recent performance trends.

2. **Error Taxonomy**

   * Automatic tagging of error types (e.g., tense, case, agreement).
   * Aggregation of most frequent errors per user.

3. **Enhanced Feedback**

   * Expanded structure: minimal pair, rule, tip, two example sentences.

4. **Spaced Repetition (Foundational)**

   * Store incorrectly answered items for re-queuing in review sessions.

5. **Regenerable Roadmap**

   * Allow user to regenerate modules within same CEFR range, preserving progress.

6. **Expanded Dialogue**

   * Three to four scenarios (e.g., Travel, Shopping, Family, Work).
   * Inline highlights and contextual vocabulary hints.

7. **Extended Statistics**

   * Display error categories and success rates by module.

---

## **Stage 3 – Admin & Content Operations**

**Objective:** Stabilize AI outputs and empower curation and control of generated content.

### **Functional Requirements**

1. **Admin CMS**

   * Approve, edit, or disable AI-generated `TaskTemplate`s.
   * Manage manually created task templates per module and language.

2. **Prompt Management**

   * Version control for all Gemini prompt templates.
   * Ability to enable, disable, or A/B test prompt versions.

3. **AI Trace Logging**

   * Store prompt, response, token count, and model metadata for each AI call.
   * Admin dashboard to view failed generations and schema violations.

4. **Error Recovery**

   * Automatic fallback to approved templates if AI output fails schema.

---

## **Stage 4 – Progress Analytics**

**Objective:** Deliver advanced insights to support learner self-assessment and instructor analytics.

### **Functional Requirements**

1. **Skill Mastery Tracking**

   * Track vocabulary, grammar, and pragmatic accuracy per module.
   * Compute per-skill mastery score (0–1 range).

2. **Timeline and CEFR Progress**

   * Weekly and monthly performance visualizations.
   * Moving CEFR estimate derived from recent accuracy and module coverage.

3. **Engagement Metrics**

   * Track time-on-task, latency, and completion rates.
   * Progress snapshots displayed via line and radar charts.

4. **Export / Reporting**

   * CSV/JSON export for academic or instructor review (optional).

---

## **Stage 5 – Gamification and Motivation Layer**

**Objective:** Strengthen user engagement and retention through structured motivational systems.

### **Functional Requirements**

1. **Badges & Levels**

   * Award badges for milestones (accuracy ≥ 85%, completing modules, daily streaks).
   * Level-up progression tied to accumulated XP.

2. **Streak Management**

   * Daily streak freeze token (one per month).
   * Streak reminder notifications (mobile/web).

3. **Leaderboards (Opt-In)**

   * Weekly XP-based leaderboard among friends or anonymized peers.

4. **User Achievements View**

   * Dedicated dashboard displaying badges, streaks, and levels.

---

## **Stage 6 – Optimization & Internationalization**

**Objective:** Optimize system performance, scalability, and accessibility for global deployment.

### **Functional Requirements**

1. **Caching & Response Reuse**

   * Cache frequently repeated AI responses (roadmaps, dialogues).
   * Use semantic keys to retrieve near-identical outputs.

2. **Streaming AI Responses**

   * Enable streamed dialogue replies to reduce latency perception.

3. **Localization (UI and Data)**

   * Full multilingual support for UI (interface translations).
   * Right-to-left (RTL) layout readiness for future languages.

4. **Offline Functionality**

   * Local caching of current module and tasks.
   * Deferred submission of attempts when offline.

5. **Performance Benchmarks**

   * API latency < 500 ms (non-AI endpoints).
   * AI cost reduction ≥ 30% through caching and reuse.

---

### **Summary Table – Stage Impact Overview**

| Stage | Title               | Focus                                            | Impact Priority |
| ----- | ------------------- | ------------------------------------------------ | --------------- |
| 1     | Super-MVP           | Core learning loop, placement → tasks → feedback | Critical        |
| 2     | MVP+                | Adaptivity, feedback quality, error taxonomy     | High            |
| 3     | Admin & Curation    | Control, traceability, AI reliability            | Medium          |
| 4     | Progress Analytics  | Insight, mastery tracking                        | Medium          |
| 5     | Gamification        | Motivation and retention                         | Low–Medium      |
| 6     | Optimization & i18n | Scalability, accessibility, performance          | Low             |

---

Would you like me to extend this into a **formal Software Requirements Specification (SRS)** format (with use cases, data entities, and acceptance criteria per feature) next? That would turn this outline into a document ready for internal or investor-level presentation.
